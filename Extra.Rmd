```{r}
# ----- Build X (T x N) from 'stock' and standardise -----
X <- stock %>%
  dplyr::select(-Date) %>%
  as.matrix()

# mean-impute each column (transparent + simple)
X <- apply(X, 2, function(x) { x[is.na(x)] <- mean(x, na.rm = TRUE); x })

# standardise over time so Euclidean distance ~ correlation structure
Y  <- scale(X)          # T x N
Yc <- t(Y)              # N x T (rows = stocks)

# preserve stock names for later plots
if (is.null(colnames(X))) colnames(X) <- paste0("S", seq_len(ncol(X)))
rownames(Yc) <- colnames(X)

```


```{r, fig.cap="Dendrogram of clustering results"}
library(MASS)    # isoMDS
library(mclust)  # Mclust, adjustedRandIndex
library(tidyverse)
library(factoextra)

# distances between stocks
d_stocks <- dist(Yc, method = "euclidean")

# Ward.D2
hc <- hclust(d_stocks, method = "ward.D2")
k  <- 3
cl_hier <- cutree(hc, k = k)

# visual check
 fviz_dend(hc, cex = 0, xlab = "",
          ylab = "", main = "",
          ggtheme = theme_bw(), lwd = 1.5,
          k = 3, rect = TRUE, color_labels_by_k = FALSE) +
  theme(text = element_text(size = 26),
        axis.text.x = element_blank(),
        plot.margin = margin(50, 20, 60, 20)) +
  coord_cartesian(clip = "off")
```

3 cluster solution is suggested, even it is not as stable as 2 cluster solution, the size of clusters would be more balanced.  

```{r, tbl.cap="Hierarchical cluster composition percentage by industry"}

hc_result <- cutree(hc, k = 3) %>% 
  as.data.frame() %>%
  rownames_to_column("stock") %>% 
  mutate(industry = substr(stock, 1, 1)) %>% 
  rename(cluster = ".")

# Count per cluster and industry, calculate percentage
cluster_industry_percent <- hc_result %>%
  group_by(cluster, industry) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(cluster) %>%
  mutate(percent = round(100 * count / sum(count), 2)) %>%
  ungroup() %>%
  dplyr::select(-count) %>%
  pivot_wider(names_from = cluster, values_from = percent, names_prefix = "Cluster_")

knitr::kable(cluster_industry_percent)
```

Cluster 1 is dominated by industry H, D, and I, cluster 2 is dominated by industry H, and E, and cluster 3 only contain cluster H.  

```{r hc_cor, fig.cap="Relationships of Hierarchical cluster 1-3 with market return"}

hc_cor <- hc_result %>% 
  right_join(long) %>% 
  group_by(cluster, Date) %>%
  summarize(mean_ret = mean(ret)) %>% 
  left_join(market) %>% 
  as.data.frame()

hc_cor_labels <- hc_cor %>%
  group_by(cluster) %>%
  summarize(
    cor = cor(MarketReturn, mean_ret, use = "complete.obs"),
    .groups = "drop"
  ) %>%
  mutate(
    label = paste0("cor = ", sprintf("%.2f", cor)),
    x = Inf,
    y = -0.1
  )

ggplot(hc_cor, aes(x = MarketReturn, y = mean_ret)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  geom_text(data = hc_cor_labels, aes(x = x, y = y, label = label),
            hjust = 1.1, vjust = 1.5, inherit.aes = FALSE) +
  facet_wrap(~cluster, ncol = 1, scales = "free_y") +
  theme_minimal() +
  labs(title = "Relationship between Hierarchical cluster 1–3 and market return",
       x = "Market Return", y = "Average Cluster Return")
```

The first 2 clusters are positively correlated with market return, while cluster 3 is slightly positive correlated. Since H is the largest industry, is highly correlated with market return, and dominates all the 3 clusters, it is not surprising that all the 3 clusters are positively correlated with market return. In relative terms, cluster 1 and 2 captures more systematic risk than cluster 3.  


```{r,  tbl.cap="Kmeans cluster composition percentage by industry"}
# k-means comparison
set.seed(1)
km <- kmeans(Yc, centers = 3, nstart = 50)

cl_km <- km$cluster

km_result <- cl_km %>% 
  as.data.frame() %>%
  rownames_to_column("stock") %>% 
  mutate(industry = substr(stock, 1, 1)) %>% 
  rename(cluster = ".")

# Count per cluster and industry, calculate percentage
km_industry_percent <- km_result %>%
  group_by(cluster, industry) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(cluster) %>%
  mutate(percent = round(100 * count / sum(count), 2)) %>%
  ungroup() %>%
  dplyr::select(-count) %>%
  pivot_wider(names_from = cluster, values_from = percent, names_prefix = "Cluster_")

knitr::kable(km_industry_percent)

```

```{r km_cor, fig.cap="Relationships of Kmeans cluster 1-3 with market return"}

km_cor <- km_result %>% 
  right_join(long) %>% 
  group_by(cluster, Date) %>%
  summarize(mean_ret = mean(ret)) %>% 
  left_join(market) %>% 
  as.data.frame()

km_cor_labels <- km_cor %>%
  group_by(cluster) %>%
  summarize(
    cor = cor(MarketReturn, mean_ret, use = "complete.obs"),
    .groups = "drop"
  ) %>%
  mutate(
    label = paste0("cor = ", sprintf("%.2f", cor)),
    x = Inf,
    y = -0.1
  )

ggplot(km_cor, aes(x = MarketReturn, y = mean_ret)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  geom_text(data = km_cor_labels, aes(x = x, y = y, label = label),
            hjust = 1.1, vjust = 1.5, inherit.aes = FALSE) +
  facet_wrap(~cluster, ncol = 1, scales = "free_y") +
  theme_minimal() +
  labs(title = "Relationship between Kmeans cluster 1–3 and market return",
       x = "Market Return", y = "Average Cluster Return")
```

The Kmeans cluster industry composition and correlation with market return are similar. Cluster 2 and 3 is highly correlated with market return, and cluster 1, which is purely formed by industry H, is slightly correlated with market return.  

```{r}
ari_hc_km <- adjustedRandIndex(cl_hier, cl_km)
ari_hc_km
```

The adjusted Rand index (ARI) between hierarchical clustering and k-means clustering is 0.35, indicating a moderate agreement between the two clustering methods. However, clustering is not considered the best suit for this data for discovering systematic risk and  idiosyncratic risk, as the clusters are highly dominated by single industry, and 2 out of 3 clusters in both solutions are highly correlated with market return.  

```{r}
# Classical MDS (2D) with fit measures
mds <- cmdscale(d_stocks, k = 2, eig = TRUE)

mds_xy <- tibble::as_tibble(mds$points, .name_repair = "minimal")
names(mds_xy) <- c("Dim1","Dim2")
mds_xy$stock      <- rownames(mds$points)
mds_xy$cluster_hc <- factor(cl_hier)

# Plot (color by hierarchical clusters; no shape mapping)
ggplot(mds_xy, aes(Dim1, Dim2, color = cluster_hc, label = stock)) +
  geom_point(alpha = 0.85) +
  geom_text(check_overlap = TRUE, size = 2, vjust = -0.5) +
  labs(title = sprintf("Classical MDS of stocks (Euclidean distance)\nGoF: %.3f / %.3f",
                       mds$GOF[1], mds$GOF[2]),
       x = "Dim1", y = "Dim2") +
  guides(shape = "none")

# Non-metric MDS (isoMDS)
iso <- isoMDS(d_stocks)
iso_xy <- tibble::as_tibble(iso$points)
names(iso_xy) <- c("Dim1","Dim2")
iso_xy$stock      <- rownames(mds$points)
iso_xy$cluster_hc <- factor(cl_hier)

ggplot(iso_xy, aes(Dim1, Dim2, color = cluster_hc, label = stock)) +
  geom_point(alpha = 0.85) +
  geom_text(check_overlap = TRUE, size = 2, vjust = -0.5) +
  labs(title = "Non-metric MDS (isoMDS)", x = "Dim1", y = "Dim2")

```

```{r}
set.seed(2)
gmm <- Mclust(Yc)                # auto-selects G and covariance by BIC
cl_gmm <- gmm$classification

# compare solutions
c(ARI_HC_vs_KM  = adjustedRandIndex(cl_hier, cl_km),
  ARI_HC_vs_GMM = adjustedRandIndex(cl_hier, cl_gmm),
  ARI_KM_vs_GMM = adjustedRandIndex(cl_km, cl_gmm))

# Plot GMM clusters on the classical MDS map
mds_xy$cluster_gmm <- factor(cl_gmm)
ggplot(mds_xy, aes(Dim1, Dim2, color = cluster_gmm, label = stock)) +
  geom_point(alpha = 0.9) +
  geom_text(check_overlap = TRUE, size = 2, vjust = -0.5) +
  labs(title = sprintf("GMM clusters on MDS map (G=%d, %s)", gmm$G, gmm$modelName),
       x = "Dim1", y = "Dim2")

```


