---
title: "High-Dimensional Analysis of Stock Returns"
Author: "Christy Lai, Sun Ma, Jiwen Zhou, Rong Xu, Sarah Liu"
format: pdf
echo: FALSE
message: FALSE
warning: FALSE
---

```{r, inlude=FALSE}
library(tidyverse)
library(visdat)
library(kableExtra)
library(pheatmap)
library(broom)
library(ggrepel)
```

# Introduction

This report examines monthly returns for up to 100 NYSE stocks (2005–2019) alongside the S&P 500 to distinguish common (systematic) movement from stock-specific variation. We map each ticker to its industry via the leading letter, then use Principal Component Analysis (PCA) and Factor Analysis (FA) to study co-movement and industry heterogeneity, and to identify stocks that most closely track the market. Before those models, we run an initial data audit and exploratory analysis to confirm the dataset is tidy, complete, and suitable for high-dimensional methods.

```{r}
# Load the data
stock <- read_csv("Data/SampleA.csv")
market <- read_csv("Data/Market.csv")
```

```{r}
# Transform to Date format
stock <- stock %>%
  mutate(
    year = str_extract(Date, "\\d{4}"),
    month = str_extract(Date, "(?<=M)\\d+"),
    month = str_pad(month, width = 2, pad = "0"),
    Date = paste0(year, "-", month),
    Date = as.Date(paste0(Date, "-01"))
  ) %>%
  select(-year, -month)

market <- market %>%
  mutate(
    year = str_extract(Date, "\\d{4}"),
    month = str_extract(Date, "(?<=M)\\d+"),
    month = str_pad(month, width = 2, pad = "0"),
    Date = paste0(year, "-", month),
    Date = as.Date(paste0(Date, "-01"))
  ) %>%
  select(-year, -month)
```


# IDA and EDA

Before proceeding to high-dimensional modelling, we conducted an initial data audit and exploratory analysis to ensure the dataset is suitable for PCA, factor modelling and other analysing approaches. This involved checking data completeness, types, summary statistics, and several visualisations.

## Data Quality and Formats

We have checked the data types and missingness patterns using the `visdat` package. The dataset contains monthly returns for various stocks and industries, but missed with Industry C, for other industries, there are no missing values. Furthermore, we verified that there are no duplicate entries and there are no missing months in the time series. The data are all numerical, except for the date column. The letter represents the industry, and the numbers represent the specific stock within that industry. The industry represented by the first letter of the stock code are as follows:

```{r}
#| tbl-cap: "Industry codes"

industry_codes <- tibble(
  Code = c("B", "C", "D", "E", "F", "G", "H", "I"),
  Industry = c(
               "Mining",
               "Construction",
               "Manufacturing",
               "Transportation and Public Utilities",
               "Wholesale Trade",
               "Retail Trade",
               "Finance, Insurance and Real Estate",
               "Services"
               )
)
```

```{r}
#| label: tbl-ind_sum
#| tbl-cap: "Industry summary statistics"

# Extract industry from stock names

long <- stock %>% 
  pivot_longer(-Date, names_to = "stock", values_to = "ret")

stock_ind <- long %>%
  mutate(ind = str_extract(stock, "^[A-Za-z]+"))

industry_prop <- stock_ind %>%  
  distinct(stock, ind) %>%       
  count(ind, name = "n_stocks") %>%
  mutate(
    prop = n_stocks / sum(n_stocks)
  ) %>%
  arrange(desc(prop))

ind_summary <- industry_codes %>%
  left_join(industry_prop, by = c("Code" = "ind")) %>%
  select(Code, Industry, n_stocks, prop) 

kable(ind_summary)
```



```{r}
#| eval: false
#Check duplicate value
stock %>% filter(duplicated(.))
```

```{r}
#| eval: false
# Check for missing months
seq_months <- tibble(Date = seq(min(stock$Date, na.rm = TRUE),
                                max(stock$Date, na.rm = TRUE),
                                by = "month"))
missing_months <- seq_months %>% 
  anti_join(stock %>% distinct(Date), by = "Date")
```


## Check for Outliers Using Z-Scores 

We identify potential outliers using the 3-sigma rule. This method flags any monthly return whose z-score exceeds ±3 standard deviations from its stock's historical mean. Z-scores were computed for each stock column individually, then reshaped and merged with the original data to inspect extreme return events.

```{r}
# Compute z-scores for each stock
stock_z <- stock %>%
  mutate(across(-Date, ~ scale(.)[, 1], .names = "{.col}_z"))

stock_z_long <- stock_z %>%
  pivot_longer(
    cols = ends_with("_z"),
    names_to = "Stock_z",
    values_to = "Z_Score"
  ) %>%
  mutate(
    Stock = str_remove(Stock_z, "_z") 
  )

# Filter rows where abs(z-score) > 3 (3-sigma outliers)
outlier_df <- stock_z_long %>%
  filter(abs(Z_Score) > 3) %>%
  select(Date, Stock, Z_Score) %>%
  arrange(desc(abs(Z_Score)))

# join with raw returns
outlier_df <- outlier_df %>%
  left_join(stock %>% 
              pivot_longer(-Date, names_to = "Stock", values_to = "Return"),
            by = c("Date", "Stock"))
```


```{r}
#| label: tbl-outlier_table
#| tbl-cap: "Top 6 outliers detected using Z-scores"
# View as tibble
top_outlier <- head(outlier_df,6)

kable(top_outlier)
```

In @tbl-outlier_table, we present the top 5 outliers with the highest absolute z-scores. For instance, stock D79122 recorded an extreme positive return of 4.15 on September 2018, corresponding to a z-score of 10.13. Other notable events occurred across several industries, including Finance (H89011, H89548, H89050) and Services (I90394), particularly clustered around the 2008–2009 period, which corresponds with the Global Financial Crisis.


```{r}
# Per-stock summary stats
summ <- long %>%
  group_by(stock) %>%
  summarise(
    mean = mean(ret, na.rm = TRUE),
    sd = sd(ret, na.rm = TRUE),
    min = min(ret, na.rm = TRUE),
    p25 = quantile(ret, 0.25, na.rm = TRUE),
    median = median(ret, na.rm = TRUE),
    p75 = quantile(ret, 0.75, na.rm = TRUE),
    max = max(ret, na.rm = TRUE),
    .groups = "drop"
  ) %>% arrange(desc(sd))
```


```{r}
#| label: tbl-statistics-table
#| tbl-cap: "Summary statistics for stock returns"
sum_table <- summ %>% slice_head(n = 9)
kable(sum_table)
```

@tbl-statistics-table summarizes the top 10 most volatile stocks by standard deviation. D79122 shows the highest volatility and return, aligning with its outlier status. While most stocks have near-zero mean returns, E88332 shows high variability with a negative mean. These results reveal substantial differences in volatility, supporting the use of PCA and factor models to identify common patterns and systematic risk drivers.


### Boxplot of top volatile stocks
```{r}
top9 <- summ %>% slice_max(sd, n = pmin(9, nrow(summ))) %>% pull(stock)
```


```{r}
#| label: fig-boxplot
#| fig-cap: "Return distributions of top 9 volatile stocks"
stock %>%
  select(Date, all_of(top9)) %>%
  pivot_longer(-Date, names_to = "stock", values_to = "ret") %>%
  ggplot(aes(stock, ret)) +
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  labs(title = "Return distributions — top9 volatile stock", 
       x = NULL, 
       y = "Monthly return") +
  theme_minimal()
```

@fig-boxplot presents return distributions for the top 9 most volatile stocks. While most returns are centered around zero, several stocks exhibit long right tails and extreme outliers—especially D79122, which exceeds a return of 4. These patterns confirm earlier findings and highlight the importance of using PCA and factor models to account for shared variation driven by high-volatility stocks.

### Industry summary

```{r}
#| label: fig-price
#| fig-cap: "Stock Price Movement by industry"

# Industry movement
ind_move <- stock_ind %>% 
  group_by(Date, ind) %>%
  summarise(mean_ret = mean(ret))

# Time series
ggplot(ind_move, aes(x = Date)) +
  geom_line(aes(y = mean_ret), color = "black") +
  facet_wrap(~ind) +
  theme_minimal() +
  labs(
    title = "Industry mean returns over time",
    x = "Date",
    y = "Return") +
  theme(legend.position = "bottom")

```

@fig-price shows that industry B, D, and E have more fluctuations, while industry F and H are more stable.  


# PCA

```{r}
#| label: fig-scree
#| fig-cap: "Scree plot of PCA"

# Prepare data for PCA
stock_pca <- stock %>% 
  select(-Date) %>% 
  as.matrix()

stock_pca_std <- scale(stock_pca)

# PCA
pca <- prcomp(stock_pca_std, 
              center = FALSE, 
              scale. = FALSE)

screeplot(pca, type = "lines")
```

PCA is conducted after standardizing the data. 3 PCs are selected as the elbow point is at PC3 in the scree plot(@fig-scree), in total explain 36% of total variance.  

```{r pca_summary}
#| label: tbl-pca-summary
#| tbl-cap: "Variance explained by PC1–PC3"
var_explained <- pca$sdev^2
prop_var <- var_explained / sum(var_explained)
cum_var <- cumsum(prop_var)

# Combine into a table
pc_summary <- data.frame(
  PC = paste0("PC", 1:length(var_explained)),
  Variance = round(var_explained, 4),
  Proportion = round(prop_var, 4),
  Cumulative = round(cum_var, 4)
)

kable(pc_summary[1:3, ])
```

As shown in @tbl-pca-summary, PC1 captures the largest portion of variance across all stock returns. In the context of financial data, this corresponds to the systematic risk, i.e., the component of returns that affects many stocks simultaneously and cannot be diversified away. 

```{r}
#| label: tbl-cor
#| tbl-cap: "Correlation between industry mean returns and market return"

ind_wide <- ind_move %>% 
  left_join(market) %>% 
  select(Date, ind, mean_ret, MarketReturn) %>%
  pivot_wider(names_from = ind, values_from = mean_ret)

ind_wide_num <- ind_wide %>%
  mutate(across(where(is.character), as.numeric)) %>% 
  as.data.frame() %>%
  select(-Date)

# Compute correlation
cor_mat <- cor(ind_wide_num, use = "pairwise.complete.obs")

# Turn into table
cor_tbl <- as.data.frame(round(cor_mat, 3))

knitr::kable(cor_tbl)
```


```{r pca_loading}
#| label: tbl-loadings
#| tbl-cap: "Industry Loadings on PC1, PC2, and PC3"

load <- as.data.frame(pca$rotation[,1:3]) %>%
  rownames_to_column("stock")

load$industry <- substr(load$stock, 1, 1)

industry_centroids <- load %>%
  group_by(industry) %>%
  summarise(PC1 = mean(PC1), 
            PC2 = mean(PC2),
            PC3 = mean(PC3))

kable(industry_centroids)
```

```{r}
#| label: fig-pca_cor
#| fig-cap: "Relationships of PC1–PC3 with market return"

scores <- as.data.frame(pca$x[, 1:3]) %>%
  cbind(Date = stock$Date, Market = market$MarketReturn)

# Standardize
scores_std <- scores %>%
  mutate(across(-Date, ~ as.numeric(scale(.))))

scores_long <- scores_std %>%
  pivot_longer(cols = c(PC1, PC2, PC3),
               names_to = "PC",
               values_to = "Score")

pca_cor_labels <- scores_long %>%
  group_by(PC) %>%
  summarize(
    cor = cor(Market, Score, use = "complete.obs"),
    .groups = "drop"
  ) %>%
  mutate(
    label = paste0("cor = ", sprintf("%.2f", cor)),
    x = Inf,
    y = Inf
  )

ggplot(scores_long, aes(x = Market, y = Score)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  geom_text(data = pca_cor_labels, aes(x = x, y = y, label = label),
            hjust = 1.1, vjust = 1.5, inherit.aes = FALSE) +
  facet_wrap(~PC, ncol = 1, scales = "free_y") +
  theme_minimal() +
  labs(title = "Relationship between PC1–PC3 and market return",
       x = "Market Return", y = "PC Score")
```

As mentioned in @tbl-cor and @tbl-loadings, industry E, H, and I are highly correlated with market return, and they all have a loading of around -0.11 for PC1, which is relatively negative compared to other industries. 

From @fig-pca_cor, it is clear that market is moving negatively with PC1, PC2 and PC3 do not show clear correlation with market return. So that industries with high importance to PC2 and PC3, industry F and B, could be considered to have unique industry variations (idiosyncratic risk).    

To summarize, industry E, H, and I are considered to contain more systematic risk, while industry F and B are considered to contain more idiosyncratic risk.

```{r}
#| label: tbl-top5-loadings
#| tbl-cap: "Top 5 Stocks by Absolute PC1 Loading"
# Extract PCA loadings for PC1
pc_load_tbl <- as.data.frame(pca$rotation[,1:3]) %>%
  rownames_to_column("stock") %>%
  mutate(
    industry = substr(stock, 1, 1),
    abs_PC1 = abs(PC1)   # absolute loadings for ranking
  ) %>%
  arrange(desc(abs_PC1))

# Top 5
top5_pc1 <- pc_load_tbl %>%
  slice_head(n = 5)

kable(top5_pc1)
```

PC1 usually represents the market-wide factor. Selecting stocks with the largest absolute loadings on PC1 identifies those most exposed to systematic risk. @tbl-top5-loadings shows the top 5 such stocks — 4 of which belong to the Finance/Real Estate sector (H), suggesting this industry plays a dominant role in systematic co-movements within the sample. While these stocks move strongly in relation to the market-wide component, the negative correlation between PC1 and the actual market return indicates an inverse relationship. Including E77520 from Transportation (E) adds sectoral diversity, making this basket a reasonable candidate for investors seeking systematic exposure.


# Factor Modelling

Building on these PCA results, we next turn to factor analysis to disentangle the structure of common versus idiosyncratic risk in greater detail. While PCA identifies PC1 as the dominant market-wide factor, factor models allow us to quantify how strongly each stock and industry loads on latent factors, and to evaluate the degree of uniqueness (idiosyncratic variation) that is not explained by systematic influences.

## Determine number of factors
```{r}
### Scree plot of eigenvalues
stock_only <- stock |> select(-Date)
X <- as.matrix(stock_only)
eig_vals <- eigen(cor(X))$values
eig_df <- data.frame(
  PC = 1:length(eig_vals),
  Eigenvalue = eig_vals
)

ggplot(eig_df, aes(x = PC, y = Eigenvalue)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(
    title = "Scree Plot of Eigenvalues",
    x = "Principal Component",
    y = "Eigenvalue"
  )

```

## Fit the Factor Model
```{r}
# Prepare matrix
stock_only <- stock %>% select(-Date)
X <- as.matrix(stock_only)

# Estimate 3-factor model with Promax rotation
fa <- factanal(X, factors = 3, rotation = "promax", 
               scores = "Bartlett", lower = 0.05)

print(fa, digits = 3, cutoff = 0.3)

```


# Appendix 
## Check missing values and data types
```{r}
#| fig-cap: "Missingness and data types"
vis_miss(stock) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
vis_dat(stock) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
```

