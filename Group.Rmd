---
title: "Group"
output: 
  bookdown::html_document2
echo: FALSE
---

```{r, inlude=FALSE}
library(tidyverse)
library(visdat)
library(pheatmap)
library(broom)
library(ggrepel)
```

# Introduction
```{r}
# Load the data
stock <- read_csv("Data/SampleA.csv")
market <- read_csv("Data/Market.csv")
```

# IDA and EDA
### Check missing values and data types
```{r}
vis_miss(stock) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
vis_dat(stock) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  )
```

```{r}
# Transform to Date format
stock <- stock %>%
  mutate(
    year = str_extract(Date, "\\d{4}"),
    month = str_extract(Date, "(?<=M)\\d+"),
    month = str_pad(month, width = 2, pad = "0"),
    Date = paste0(year, "-", month),
    Date = as.Date(paste0(Date, "-01"))
  ) %>%
  select(-year, -month)

market <- market %>%
  mutate(
    year = str_extract(Date, "\\d{4}"),
    month = str_extract(Date, "(?<=M)\\d+"),
    month = str_pad(month, width = 2, pad = "0"),
    Date = paste0(year, "-", month),
    Date = as.Date(paste0(Date, "-01"))
  ) %>%
  select(-year, -month)
```

### Check for outliers using z-scores 

```{r}
# Compute z-scores for each stock
stock_z <- stock %>%
  mutate(across(-Date, ~ scale(.)[, 1], .names = "{.col}_z"))

stock_z_long <- stock_z %>%
  pivot_longer(
    cols = ends_with("_z"),
    names_to = "Stock_z",
    values_to = "Z_Score"
  ) %>%
  mutate(
    Stock = str_remove(Stock_z, "_z") 
  )

# Filter rows where abs(z-score) > 3 (3-sigma outliers)
outlier_df <- stock_z_long %>%
  filter(abs(Z_Score) > 3) %>%
  select(Date, Stock, Z_Score) %>%
  arrange(desc(abs(Z_Score)))

# join with raw returns
outlier_df <- outlier_df %>%
  left_join(stock %>% 
              pivot_longer(-Date, names_to = "Stock", values_to = "Return"),
            by = c("Date", "Stock"))

# View as tibble
top_outlier <- head(outlier_df,5)
```

```{r}
# Per-stock summary stats
long <- stock %>% 
  pivot_longer(-Date, names_to = "stock", values_to = "ret")
summ <- long %>%
  group_by(stock) %>%
  summarise(
    n = sum(!is.na(ret)),
    miss_rate = mean(is.na(ret)),
    mean = mean(ret, na.rm = TRUE),
    sd = sd(ret, na.rm = TRUE),
    min = min(ret, na.rm = TRUE),
    p25 = quantile(ret, 0.25, na.rm = TRUE),
    median = median(ret, na.rm = TRUE),
    p75 = quantile(ret, 0.75, na.rm = TRUE),
    max = max(ret, na.rm = TRUE),
    .groups = "drop"
  ) %>% arrange(desc(sd))
summ %>% slice_head(n = 12)
```

### Boxplot of top volatile stocks
```{r}
top9 <- summ %>% slice_max(sd, n = pmin(9, nrow(summ))) %>% pull(stock)
stock %>%
  select(Date, all_of(top9)) %>%
  pivot_longer(-Date, names_to = "stock", values_to = "ret") %>%
  ggplot(aes(stock, ret)) +
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  labs(title = "Return distributions — top9 volatile stock", x = NULL, y = "Monthly return") +
  theme_minimal()
```

### Time series of top volatile stocks
```{r}
stock %>%
  select(Date, all_of(top9)) %>%
  pivot_longer(-Date, names_to = "stock", values_to = "ret") %>%
  ggplot(aes(Date, ret)) +
  geom_line(linewidth = 0.3) +
  facet_wrap(~ stock, scales = "free_y") +
  labs(title = "Monthly returns over time — top9 volatile stock", x = NULL, y = "Return") +
  theme_minimal()
```

### Check duplicates
```{r}
#Check duplicate value
stock %>% filter(duplicated(.))
```

### Check for missing months
```{r}
# Check for missing months
seq_months <- tibble(Date = seq(min(stock$Date, na.rm = TRUE),
                                max(stock$Date, na.rm = TRUE),
                                by = "month"))
missing_months <- seq_months %>% 
  anti_join(stock %>% distinct(Date), by = "Date")
```

### Industry summary

```{r, tbl.cap="Industry summary statistics"}}

# Extract industry from stock names
stock_ind <- long %>%
  mutate(ind = str_extract(stock, "^[A-Za-z]+"))

ind_summary <- stock_ind %>%
  group_by(ind) %>%
  summarise(
    n_stocks = n_distinct(stock),
    mean_ret = mean(ret, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange()

knitr::kable(ind_summary)
```

H is the largest industry while B and G are the smallest. Industry D has the highest mean return, while industry G has the lowest.  

```{r, fig.cap="Stock Price Movement by industry"}

# Industry movement
ind_move <- stock_ind %>% 
  group_by(Date, ind) %>%
  summarise(mean_ret = mean(ret))

# Time series
ggplot(ind_move, aes(x = Date)) +
  geom_line(aes(y = mean_ret), color = "black") +
  facet_wrap(~ind) +
  theme_minimal() +
  labs(
    title = "Industry mean returns over time",
    x = "Date",
    y = "Return") +
  theme(legend.position = "bottom")

```

Industry B, D, and E have more fluctuations, while industry F and H are more stable.  

```{r cor, tbl.cap="Correlation between industry mean returns and market return"}
ind_wide <- ind_move %>% 
  left_join(market) %>% 
  select(Date, ind, mean_ret, MarketReturn) %>%
  pivot_wider(names_from = ind, values_from = mean_ret)

ind_wide_num <- ind_wide %>%
  mutate(across(where(is.character), as.numeric)) %>% 
  as.data.frame() %>%
  select(-Date)

# Compute correlation
cor_mat <- cor(ind_wide_num, use = "pairwise.complete.obs")

# Turn into table
cor_tbl <- as.data.frame(round(cor_mat, 3))

knitr::kable(cor_tbl)
```

Industry I, H, and E are highly correlated with market return, and with each other. Industry G is the least correlated.  

```{r}


# stock: has columns Date + stock return columns
# market: has columns Date + MarketReturn

# 1. Long format
long <- stock %>%
  pivot_longer(-Date, names_to = "stock", values_to = "ret") %>%
  left_join(market, by = "Date")

# 2. Correlations with market
stock_mkt_cor <- long %>%
  group_by(stock) %>%
  summarise(
    cor_with_market = cor(ret, MarketReturn, use = "complete.obs"),
    n_obs = sum(!is.na(ret) & !is.na(MarketReturn)),
    .groups = "drop"
  ) %>%
  arrange(desc(cor_with_market))

# 3. Preview top & bottom movers
head(stock_mkt_cor, 10)    # 10 most correlated with market
tail(stock_mkt_cor, 10)    # 10 least correlated with market



```


# PCA

```{r scree, fig.cap="Scree plot of PCA"}
# Prepare data for PCA
stock_pca <- stock %>% 
  select(-Date) %>% 
  as.matrix()

stock_pca_std <- scale(stock_pca)

# PCA
pca <- prcomp(stock_pca_std, 
              center = FALSE, 
              scale. = FALSE)

screeplot(pca, type = "lines")
```

PCA is conducted after standardizing the data. 3 PCs are selected as the elbow point is at PC3 in the scree plot, in total explain 36% of total variance.  

```{r pc12, fig.cap="Centroids of industries on PC1 & PC2"}
# Get PC1 and PC2 industry scores
load <- as.data.frame(pca$rotation[,1:3]) %>%
  rownames_to_column("stock")

load$industry <- substr(load$stock, 1, 1)

readr::write_csv(load, "Data/pca_loadings.csv")

industry_centroids <- load %>%
  group_by(industry) %>%
  summarise(PC1 = mean(PC1), 
            PC2 = mean(PC2),
            PC3 = mean(PC3))

# Plot centroids
ggplot(industry_centroids, 
       aes(PC1, PC2, color = industry)) +
  geom_point(size=4) +
  geom_text(aes(label = industry), hjust=-1, vjust=-0.5) +
  theme_minimal() +
  labs(title="Industry centroids on PC1 & PC2") + 
  guides(color = "none")
```

The industry centroids show that industry D (Manufacturing), G (Retail Trade) are high on PC1, industry H (Finance, Insurance and Real Estate), B (Mining) are high on PC2, and industry F (Wholesale Trade) is high on both, which is considered an outlier. Industry B (Mining) is very high on PC3. PC1 captures the largest portion of variance across all stock returns. In the context of financial data, this corresponds to the systematic risk, i.e., the component of returns that affects many stocks simultaneously and cannot be diversified away. As mentioned, industry E, H, and I are highly correlated with market return, and they all have a loading of around -0.11 for PC1, which is relatively negative compared to other industries. PC1 could then be considered slightly negatively correlated with market return, and details would be explored later. Since the PC2 are uncorrelated, industries with high importance to PC2 and PC3, industry F and B, could be considered to have unique industry variations (idiosyncratic risk).  


## PCA Biplot
```{r}
loadings <- as.data.frame(pca$rotation[,1:3]) %>% 
  rownames_to_column("stock")

ggplot(loadings, aes(PC1, PC2, color = substr(stock,1,1))) +
  geom_point() +
  geom_text_repel(aes(label=stock), size=2) +
  theme_minimal() + 
 ggtitle("PCA Biplot")
```
PC1 (x-axis): This is the first principal component, explaining the largest share of variance across stock returns. Stocks positioned to the left or right differ mainly in how much they load on systematic variation captured by PC1.

PC2 (y-axis): The second principal component, orthogonal to PC1, captures the second-largest independent source of variation. Stocks placed higher or lower reflect differences in this secondary risk/return structure.

Together, PC1 and PC2 capture the two dominant risk factors driving stock co-movements in your dataset.

Stocks with strong loadings on PC1 and small loadings on PC2 are better candidates — they align with the broad market factor rather than unique sector dynamics.

From the plot, these tend to be clustered around the negative side of PC1 with small PC2 loadings (middle-right area).

Conversely, stocks with extreme positive/negative PC2 loadings may reflect unique sector risks and are less suitable as “market representatives.”

This PCA biplot shows how stocks from different industries align on the first two principal components. PC1 captures systematic market risk, while PC2 distinguishes industry-specific or idiosyncratic effects. Industry H stocks drive PC2 variation, while D and E cluster tightly around the systematic factor. For market-representative stock selection, focus on those with strong PC1 loadings and minimal PC2 influence


```{r pca_ts, tbl.cap="Time series of PC1–PC3 with market return"}

scores <- as.data.frame(pca$x[, 1:3]) %>%
  cbind(Date = stock$Date, Market = market$MarketReturn)

# Standardize
scores_std <- scores %>%
  mutate(across(-Date, ~ as.numeric(scale(.))))

scores_long <- scores_std %>%
  pivot_longer(cols = c(PC1, PC2, PC3),
               names_to = "PC",
               values_to = "Score")

# Plot time series
ggplot(scores_long, aes(x = Date)) +
  geom_line(aes(y = Score)) +
  geom_line(aes(y = Market), color = "red", alpha = 0.6) +
  facet_wrap(~PC, ncol = 1, scales = "free_y") +
  theme_minimal() +
  labs(title = "PC1–PC3 vs Market Return (Standardized)",
       x = "Date", y = "Standardized Value",
       caption = "Red line = Market return") +
  theme(legend.position = "none")

```

```{r pca_cor, tbl.cap="Relationships of PC1–PC3 with market return"}

pca_cor_labels <- scores_long %>%
  group_by(PC) %>%
  summarize(
    cor = cor(Market, Score, use = "complete.obs"),
    .groups = "drop"
  ) %>%
  mutate(
    label = paste0("cor = ", sprintf("%.2f", cor)),
    x = Inf,
    y = Inf
  )

ggplot(scores_long, aes(x = Market, y = Score)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  geom_text(data = pca_cor_labels, aes(x = x, y = y, label = label),
            hjust = 1.1, vjust = 1.5, inherit.aes = FALSE) +
  facet_wrap(~PC, ncol = 1, scales = "free_y") +
  theme_minimal() +
  labs(title = "Relationship between PC1–PC3 and market return",
       x = "Market Return", y = "PC Score")
```

It is clear that market is moving negatively with PC1, PC2 is slightly negative, and PC3 do not show clear coorrelation with market return. This confirms the earlier observation that PC1 is slightly negatively correlated with market return.  

To summarize, industry E, H, and I are considered to contain more systematic risk, while industry F and B are considered to contain more idiosyncratic risk.  

# References

```{r pca_summary, tbl.cap="Variance explained by PC1–PC3"}
var_explained <- pca$sdev^2
prop_var <- var_explained / sum(var_explained)
cum_var <- cumsum(prop_var)

# Combine into a table
pc_summary <- data.frame(
  PC = paste0("PC", 1:length(var_explained)),
  Variance = round(var_explained, 4),
  Proportion = round(prop_var, 4),
  Cumulative = round(cum_var, 4)
)

knitr::kable(pc_summary[1:3, ])
```


```{r pca_loading, tbl.cap="Loadings by Industry for PC1, PC2, PC3"}

knitr::kable(industry_centroids)
```

```{r}
### Count stocks per industry
stock_counts <- stock %>%
  select(-Date) %>%
  colnames() %>%
  tibble(stock = .) %>%
  mutate(industry = substr(stock, 1, 1)) %>%
  count(industry, name = "n_stocks") %>%
  mutate(share = round(100 * n_stocks / sum(n_stocks), 1))

knitr::kable(stock_counts, caption = "Number of stocks per industry in dataset")

```

## Factor Modelling
```{r}
### Scree plot of eigenvalues
stock_only <- stock |> select(-Date)
X <- as.matrix(stock_only)
eig_vals <- eigen(cor(X))$values
eig_df <- data.frame(
  PC = 1:length(eig_vals),
  Eigenvalue = eig_vals
)

ggplot(eig_df, aes(x = PC, y = Eigenvalue)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(
    title = "Scree Plot of Eigenvalues",
    x = "Principal Component",
    y = "Eigenvalue"
  )

```

```{r}
# Use correlation matrix eigenvalues for a quick factor count (Kaiser is liberal; cap at 5)

eig_vals <- eigen(cor(X))$values
kaiser_k <- sum(eig_vals > 1)
k <- min(3, kaiser_k)

# Fit factor model with easier convergence per assignment hint
fa <- factanal(X, factors = k, rotation = "promax",
               scores = "Bartlett", lower = 0.05)

print(fa, digits = 3, cutoff = 0.3)

# Industry-average loadings (Factor1..FactorK)
fa_load <- as_tibble(unclass(fa$loadings), rownames = "stock") %>%
  mutate(industry = substr(stock, 1, 1)) %>%
  group_by(industry) %>%
  summarise(across(starts_with("Factor"), ~ mean(.x, na.rm = TRUE)), .groups = "drop")

```




```{r}
#scree plot
fa_promax <- factanal(X, factors = k, rotation = "promax",
               scores = "Bartlett", lower = 0.05)

fa_promax_df <- tidy(fa_promax)

ggplot(fa_promax_df,aes(x=fl1,y=fl2, label=variable))+
geom_segment(aes(xend=fl1, yend=fl2,x=0,y=0),
arrow = arrow())+ geom_text(color='red',nudge_y = -0.05)




```

```{r}
# install.packages("ggrepel")  # run once
library(ggplot2)
library(ggrepel)
# library(broom)  # if you need tidy()

fa_promax <- factanal(X, factors = k, rotation = "promax",
                      scores = "Bartlett", lower = 0.05)

fa_promax_df <- tidy(fa_promax)  # assumes columns: variable, fl1, fl2

ggplot(fa_promax_df, aes(x = fl1, y = fl2, label = variable)) +
  geom_segment(aes(x = 0, y = 0, xend = fl1, yend = fl2),
               arrow = arrow(length = unit(2, "mm")), linewidth = 0.2) +
  geom_point(size = 0) +
  geom_text_repel(
    max.overlaps = Inf,       # repel instead of dropping labels
    box.padding = 0.25,       # space around labels
    point.padding = 0.1,
    min.segment.length = 0,   # always draw leader lines if needed
    seed = 123,               # reproducible placement
    color = "red",            # keep your red labels
    size = 3
  ) +
  coord_equal() +
  expand_limits(x = c(-1.1, 1.1), y = c(-1.1, 1.1)) +
  theme_minimal()



```

# Table of both Factor model loading, uniqueness and PCA loadings
```{r}
library(tidyverse)

# 1. Factor Analysis loadings + uniqueness
fa_tbl <- as_tibble(unclass(fa$loadings), rownames = "stock") %>%
  rename(F1 = Factor1, F2 = Factor2, F3 = Factor3)

uniq_tbl <- tibble(stock = names(fa$uniquenesses),
                   uniqueness = as.numeric(fa$uniquenesses))

fa_tbl <- fa_tbl %>%
  left_join(uniq_tbl, by = "stock")

# 2. PCA loadings (rotation)
pc_tbl <- as.data.frame(pca$rotation[,1:3]) %>%
  rownames_to_column("stock") %>%
  rename(PC1 = PC1, PC2 = PC2, PC3 = PC3)

# 3. Combine both
rank_tbl <- fa_tbl %>%
  left_join(pc_tbl, by = "stock") %>%
  mutate(industry = substr(stock, 1, 1)) %>%
  arrange(uniqueness)

# 4. Save to CSV for inspection
write_csv(rank_tbl, "outputs/uniqueness_rank_with_loadings.csv")

# 5. Preview top 10
rank_tbl %>%
  select(stock, industry, uniqueness, F1, F2, F3, PC1, PC2, PC3) %>%
  slice_head(n = 10)

```

#conclusion
H89190, lowerst uniqueness and loading in factor 1 is high
H89050, u - 0.233, f3 0.923, PC1 0.142, PC2 -0.099 close to 0


H90000, lowest uniqueness 0.05, PCA high PC1 low PC2

H76273, factor 1 0.849, uniqueness 0.433
H75157, factor 3 0.933, uniqueness 

